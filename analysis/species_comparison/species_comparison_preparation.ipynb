{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Species comparison: preparation\n",
    "\n",
    "**Purpose**: To prepare datasets for a comparison of cleavage sites between yeast species and human.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i notebook_setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTS AND SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paper_utilities import cleavage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT   = \"/projects/b1080/eks/polyadenylation/yeast\"\n",
    "DATADIR   = os.path.join(PROJECT, 'external_data', 'conservation')\n",
    "OUTDIR    = os.path.join(PROJECT, 'manuscript', 'analysis', 'species_comparison')\n",
    "RESOURCES = os.path.join(os.path.dirname(OUTDIR), 'resources')\n",
    "os.makedirs(OUTDIR, exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load motif family definitions for S. cerevisiae\n",
    "\n",
    "scer_definitions = {'patterns' : {}, 'distance' : {}}\n",
    "\n",
    "# By pattern - we only look at pattern families for 6mers\n",
    "with open(os.path.join(RESOURCES, f'motif_definitions.scer.6mers.patterns.pickle'), mode = 'rb') as handle:\n",
    "    scer_definitions['patterns'][6] = pickle.load(handle)\n",
    "    \n",
    "scer_definitions['patterns'][5] = {'family':{}}\n",
    "scer_definitions['patterns'][4] = {'family':{}}\n",
    "\n",
    "# By Hamming distance\n",
    "for kmer in [4,5,6]:\n",
    "    with open(os.path.join(RESOURCES, f'motif_definitions.scer.{kmer}mers.distance.pickle'), mode = 'rb') as handle:\n",
    "        scer_definitions['distance'][kmer] = pickle.load(handle)\n",
    "\n",
    "        \n",
    "## Load motif family definitions for S. pombe\n",
    "\n",
    "spom_definitions = {'patterns' : {}, 'distance' : {}}\n",
    "\n",
    "# By Hamming distance\n",
    "for kmer in [4,5,6]:\n",
    "    with open(os.path.join(RESOURCES, f'motif_definitions.spom.{kmer}mers.distance.pickle'), mode = 'rb') as handle:\n",
    "        spom_definitions['distance'][kmer] = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant motifs: scer=137, spom=230\n"
     ]
    }
   ],
   "source": [
    "## Load significant motifs for each species\n",
    "\n",
    "with open(os.path.join(RESOURCES, 'polyaclassifier_motifs.significant_motifs.pickle'), mode = 'rb') as handle:\n",
    "    significant_motifs = pickle.load(handle)\n",
    "    \n",
    "sigmots_scer = significant_motifs['saccharomyces_cerevisiae']['polyaclassifier']['polyaclassifier_bagging3_kmers-6']\n",
    "sigmots_spom = significant_motifs['schizosaccharomyces_pombe']['polyaclassifier']['polyaclassifier_bagging3_kmers-6']\n",
    "\n",
    "print(f\"Significant motifs: scer={len(sigmots_scer)}, spom={len(sigmots_spom)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELPER FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy_cutoffs(data, species, percentiles):\n",
    "    return data.loc[data['species'] == species, 'observed_entropy'].quantile(percentiles).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_position(data):\n",
    "    \n",
    "    ##\n",
    "    \n",
    "    sites = {}\n",
    "\n",
    "    for i,row in tqdm.tqdm(data.iterrows()):\n",
    "\n",
    "        rowkey = (row['gene'],row['chrom'],row['strand'])\n",
    "\n",
    "        if not (rowkey in sites):\n",
    "            sites[rowkey] = [row['start']]\n",
    "        else:\n",
    "            sites[rowkey].append(row['start'])\n",
    "            \n",
    "    ## \n",
    "    \n",
    "    sites_labels = {}\n",
    "\n",
    "    for rk,pl in sites.items():\n",
    "\n",
    "        sites_labels[rk] = {}\n",
    "\n",
    "        if (len(pl) == 1):\n",
    "            sites_labels[rk][pl[0]] = 'single'\n",
    "\n",
    "        else:\n",
    "            spl = sorted(pl)\n",
    "            g,c,s = rk\n",
    "\n",
    "            sites_labels[rk][spl[0]] = 'first' if (s == '+') else 'last'\n",
    "            sites_labels[rk][spl[-1]] = 'last' if (s == '+') else 'first'\n",
    "\n",
    "            for p in spl[1:-1]:\n",
    "                sites_labels[rk][p] = 'middle'\n",
    "    \n",
    "    return data.apply(lambda row : sites_labels.get((row['gene'],row['chrom'],row['strand']), {}).get(row['start'], 'NA'), axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_order = ['S.cerevisiae','S.pombe','H.sapiens']\n",
    "\n",
    "species_palette = {\n",
    "    'S.cerevisiae' : sns.color_palette(\"Set2\")[0],\n",
    "    'S.pombe'      : sns.color_palette(\"Set2\")[1],\n",
    "    'H.sapiens'    : sns.color_palette(\"Set2\")[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare gene homology information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile a list of gene names and Ensembl IDs for *H. sapiens* from annotation GTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsap_gene_data  = pd.read_csv(os.path.join(PROJECT, 'homo_sapiens', 'reference', 'annotation', 'annotation.biotype.info'), sep = \"\\t\")\n",
    "hsap_gene_names = hsap_gene_data[['geneId','geneName']].drop_duplicates()\n",
    "hsap_gene_map   = dict(zip(hsap_gene_names['geneId'], hsap_gene_names['geneName']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile a list of gene names and aliases for *S. cerevisiae* from SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8012, 16)\n",
      "5424\n",
      "20181\n",
      "[('YAL069W', 'YAL069W'), ('YAL068W-A', 'YAL068W-A'), ('ARS102', 'ARS102'), ('ARSI-1', 'ARS102'), ('TEL01L', 'TEL01L')]\n"
     ]
    }
   ],
   "source": [
    "scer_gene_data = pd.read_csv(os.path.join(DATADIR, 'homologous_genes', 'sgd', 'SGD_features.txt'), sep = '\\t')\n",
    "scer_gene_data = scer_gene_data.loc[scer_gene_data['ParentFeatureName'].str.contains('chromosome') == True]\n",
    "\n",
    "print(scer_gene_data.shape)\n",
    "print(scer_gene_data['StandardGeneName'].str.contains(\"|\").sum())\n",
    "\n",
    "scer_synonyms = {}\n",
    "\n",
    "for fname, sname, aliases in zip(scer_gene_data['FeatureName'], scer_gene_data['StandardGeneName'], scer_gene_data['Alias']):\n",
    "    \n",
    "    scer_synonyms[fname] = fname\n",
    "    \n",
    "    if (str(sname) != \"nan\"):\n",
    "        for _ in sname.split(\"|\"):\n",
    "            scer_synonyms[_] = fname\n",
    "            \n",
    "    if (str(aliases) != \"nan\"):\n",
    "        for _ in aliases.split(\"|\"):\n",
    "            scer_synonyms[_] = fname\n",
    "    \n",
    "print(len(list(scer_synonyms.keys())))\n",
    "print(list(scer_synonyms.items())[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile a list of homologous genes according from PomBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape     : (5121, 3)\n",
      "Exploded shape  : (22859, 3)\n",
      "No missing shape: (17068, 3)\n"
     ]
    }
   ],
   "source": [
    "gene_homologs = pd.read_csv(os.path.join(DATADIR, 'homologous_genes', 'pombase', 'pombe-cerevisiae-human-orthologs.txt'), sep = \"\\t\", dtype = str)\n",
    "print(\"Input shape     :\", gene_homologs.shape)\n",
    "\n",
    "gene_homologs['cerevisiaeOrthologs'] = gene_homologs['cerevisiaeOrthologs'].apply(lambda x : x.split(\"|\"))\n",
    "gene_homologs['humanOrthologs']      = gene_homologs['humanOrthologs'].apply(lambda x : x.split(\"|\"))\n",
    "\n",
    "gene_homologs = gene_homologs.explode('cerevisiaeOrthologs')\n",
    "gene_homologs = gene_homologs.explode('humanOrthologs')\n",
    "print(\"Exploded shape  :\", gene_homologs.shape)\n",
    "\n",
    "## Remove genes where there is not both a S.cer and H.sap ortholog\n",
    "\n",
    "condC1 = ~(gene_homologs['cerevisiaeOrthologs'].isna())\n",
    "condC2 = ~(gene_homologs['cerevisiaeOrthologs'] == 'NONE')\n",
    "condH1 = ~(gene_homologs['humanOrthologs'].isna())\n",
    "condH2 = ~(gene_homologs['humanOrthologs'] == 'NONE')\n",
    "\n",
    "gene_homologs = gene_homologs.loc[condC1 & condC2 & condH1 & condH2].copy()\n",
    "print(\"No missing shape:\", gene_homologs.shape)\n",
    "\n",
    "with open(os.path.join(RESOURCES, 'homologous_genes.df.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(gene_homologs, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S. cer: 3406 3410\n",
      "S. pom: 3262\n",
      "H. sap: 4086\n"
     ]
    }
   ],
   "source": [
    "homologs_scer = sorted(list([scer_synonyms[x] for x in gene_homologs['cerevisiaeOrthologs'].unique().tolist() if (x in scer_synonyms)]))\n",
    "homologs_spom = sorted(gene_homologs['pombeGene'].unique().tolist())\n",
    "homologs_hsap = sorted(gene_homologs['humanOrthologs'].unique().tolist())\n",
    "\n",
    "print(\"S. cer:\", len(homologs_scer), gene_homologs['cerevisiaeOrthologs'].nunique())\n",
    "print(\"S. pom:\", len(homologs_spom))\n",
    "print(\"H. sap:\", len(homologs_hsap))\n",
    "\n",
    "homologs_lists = {\n",
    "    'scer' : homologs_scer,\n",
    "    'spom' : homologs_spom,\n",
    "    'hsap' : homologs_hsap,\n",
    "}\n",
    "\n",
    "with open(os.path.join(RESOURCES, 'homologous_genes.lists.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(homologs_lists, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile dictionary mapping homologous genes across species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10751\n"
     ]
    }
   ],
   "source": [
    "homologs_map = {}\n",
    "\n",
    "for i,row in gene_homologs.iterrows():\n",
    "    \n",
    "    pOrtholog = row['pombeGene']\n",
    "    cOrtholog = row['cerevisiaeOrthologs']\n",
    "    hOrtholog = row['humanOrthologs']\n",
    "            \n",
    "    if (cOrtholog not in scer_synonyms):\n",
    "        continue\n",
    "        \n",
    "    cOrtholog = scer_synonyms[cOrtholog]\n",
    "\n",
    "    homologs_map[f'scer_{cOrtholog}'] = {'scer': cOrtholog, 'spom': pOrtholog, 'hsap': hOrtholog}\n",
    "    homologs_map[f'spom_{pOrtholog}'] = {'scer': cOrtholog, 'spom': pOrtholog, 'hsap': hOrtholog}\n",
    "    homologs_map[f'hsap_{hOrtholog}'] = {'scer': cOrtholog, 'spom': pOrtholog, 'hsap': hOrtholog}\n",
    "    \n",
    "print(len(list(homologs_map.keys())))\n",
    "\n",
    "with open(os.path.join(RESOURCES, 'homologous_genes.map.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(homologs_map, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate conservation in coding regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esk863/.conda/envs/tf-train/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "cds_scer = pd.read_csv(os.path.join(PROJECT, \"saccharomyces_cerevisiae/analysis/conservation/site_conservation.annotation_coding.exons.window_-1.txt\"), sep = \"\\t\")\n",
    "cds_spom = pd.read_csv(os.path.join(PROJECT, \"schizosaccharomyces_pombe/analysis/conservation/site_conservation.annotation_coding.exons.window_-1.txt\"), sep = \"\\t\")\n",
    "cds_hsap = pd.read_csv(os.path.join(PROJECT, \"homo_sapiens/analysis/conservation/site_conservation.annotation_coding.exons.window_-1.txt\"), sep = \"\\t\")\n",
    "\n",
    "cds_scer['conservation'] = cds_scer['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\", \")]))\n",
    "cds_spom['conservation'] = cds_spom['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\", \")]))\n",
    "cds_hsap['conservation'] = cds_hsap['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\", \")]))\n",
    "\n",
    "cds_score_scer = np.nan_to_num(np.concatenate(cds_scer['conservation'].tolist()), nan=0)\n",
    "cds_mean_scer  = np.mean(cds_score_scer)\n",
    "cds_stdv_scer  = np.std(cds_score_scer)\n",
    "\n",
    "cds_score_spom = np.nan_to_num(np.concatenate(cds_spom['conservation'].tolist()), nan=0)\n",
    "cds_mean_spom  = np.mean(cds_score_spom)\n",
    "cds_stdv_spom  = np.std(cds_score_spom)\n",
    "\n",
    "cds_score_hsap = np.nan_to_num(np.concatenate(cds_hsap['conservation'].tolist()), nan=0)\n",
    "cds_mean_hsap  = np.mean(cds_score_hsap)\n",
    "cds_stdv_hsap  = np.std(cds_score_hsap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.cerevisiae: (8719615,) 0.7136361543485581 0.3848678468477208\n",
      "S.pombe     : (7169805,) 2.161310019881989 1.1171600102972692\n",
      "H.sapiens   : (35861309,) 0.6695558514609706 0.44467385293130146\n"
     ]
    }
   ],
   "source": [
    "print(\"S.cerevisiae:\", np.shape(cds_score_scer), cds_mean_scer, cds_stdv_scer)\n",
    "print(\"S.pombe     :\", np.shape(cds_score_spom), cds_mean_spom, cds_stdv_spom)\n",
    "print(\"H.sapiens   :\", np.shape(cds_score_hsap), cds_mean_hsap, cds_stdv_hsap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds_scores = {\n",
    "    'scer' : {'mean': cds_mean_scer, 'stdv': cds_stdv_scer},\n",
    "    'spom' : {'mean': cds_mean_spom, 'stdv': cds_stdv_spom},\n",
    "    'hsap' : {'mean': cds_mean_hsap, 'stdv': cds_stdv_hsap},\n",
    "}\n",
    "\n",
    "with open(os.path.join(RESOURCES, 'conservation.cds_scores.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(cds_scores, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conservation meta-analysis around polyA sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare conservation data surrounding top polyA sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify polyA sites in homologous genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.cerevisiae: conserved=3296 not_conserved=2225\n",
      "S.pombe     : conserved=2720 not_conserved=1260\n",
      "H.sapiens   : conserved=3777 not_conserved=12325\n"
     ]
    }
   ],
   "source": [
    "top1_scer = pd.read_csv(os.path.join(PROJECT, \"saccharomyces_cerevisiae/analysis/conservation/site_conservation.golden_sites.top-1.window_500.txt\"), sep = \"\\t\")\n",
    "top1_spom = pd.read_csv(os.path.join(PROJECT, \"schizosaccharomyces_pombe/analysis/conservation/site_conservation.golden_sites.top-1.window_500.txt\"), sep = \"\\t\")\n",
    "top1_hsap = pd.read_csv(os.path.join(PROJECT, \"homo_sapiens/analysis/conservation/site_conservation.golden_sites.top-1.window_500.txt\"), sep = \"\\t\")\n",
    "\n",
    "top1_scer['species'] = 'S.cerevisiae'\n",
    "top1_spom['species'] = 'S.pombe'\n",
    "top1_hsap['species'] = 'H.sapiens'\n",
    "\n",
    "top1_scer['featureName'] = top1_scer['gene'].apply(lambda x : scer_synonyms.get(x,np.nan))\n",
    "top1_spom['featureName'] = top1_spom['gene']\n",
    "top1_hsap['featureName'] = top1_hsap['gene'].apply(lambda x : hsap_gene_map.get(x,np.nan))\n",
    "\n",
    "top1_scer['conserved_yeast_to_human'] = top1_scer['featureName'].isin(homologs_scer)\n",
    "top1_spom['conserved_yeast_to_human'] = top1_spom['featureName'].isin(homologs_spom)\n",
    "top1_hsap['conserved_yeast_to_human'] = top1_hsap['featureName'].isin(homologs_hsap)\n",
    "\n",
    "print(f\"S.cerevisiae: conserved={(top1_scer['conserved_yeast_to_human'] == True).sum()} not_conserved={(top1_scer['conserved_yeast_to_human'] == False).sum()}\")\n",
    "print(f\"S.pombe     : conserved={(top1_spom['conserved_yeast_to_human'] == True).sum()} not_conserved={(top1_spom['conserved_yeast_to_human'] == False).sum()}\")\n",
    "print(f\"H.sapiens   : conserved={(top1_hsap['conserved_yeast_to_human'] == True).sum()} not_conserved={(top1_hsap['conserved_yeast_to_human'] == False).sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate conservation and entropy surrounding polyA sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25603, 19)\n"
     ]
    }
   ],
   "source": [
    "top1_data = pd.concat([top1_scer, top1_spom, top1_hsap], ignore_index = True, sort = False)\n",
    "\n",
    "top1_data['conservation']     = top1_data['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "top1_data['readvec']          = top1_data['readvec'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "top1_data['observed_norm']    = top1_data['readvec'].apply(lambda x: x / np.sum(x))\n",
    "top1_data['observed_entropy'] = top1_data['observed_norm'].apply(lambda x : cleavage.calculate_entropy_from_vector(x))\n",
    "\n",
    "print(top1_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sort polyA sites into entropy groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy group cutoffs for S.cer: [0, 2.0427309708591617, 2.761882046212095, 4]\n",
      "Entropy group cutoffs for S.pom: [0, 1.4555478464625482, 2.272820318029907, 4]\n",
      "Entropy group cutoffs for H.sap: [0, 1.1828515661854353, 2.0065811389742, 4]\n",
      "\n",
      "Entropy group counts by species:\n",
      "species       observed_entropy_bin\n",
      "H.sapiens     H                       3221\n",
      "              L                       3221\n",
      "              M                       9660\n",
      "S.cerevisiae  H                       1104\n",
      "              L                       1105\n",
      "              M                       3312\n",
      "S.pombe       H                        796\n",
      "              L                        796\n",
      "              M                       2388\n",
      "Name: observed_entropy_bin, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "entropy_cutoffs_scer = [0] + calculate_entropy_cutoffs(top1_data, 'S.cerevisiae', [0.2,0.8]) + [4]\n",
    "entropy_cutoffs_spom = [0] + calculate_entropy_cutoffs(top1_data, 'S.pombe',      [0.2,0.8]) + [4]\n",
    "entropy_cutoffs_hsap = [0] + calculate_entropy_cutoffs(top1_data, 'H.sapiens',    [0.2,0.8]) + [4]\n",
    "\n",
    "print(f\"Entropy group cutoffs for S.cer: {entropy_cutoffs_scer}\")\n",
    "print(f\"Entropy group cutoffs for S.pom: {entropy_cutoffs_spom}\")\n",
    "print(f\"Entropy group cutoffs for H.sap: {entropy_cutoffs_hsap}\")\n",
    "\n",
    "top1_data.loc[top1_data['species'] == 'S.cerevisiae', 'observed_entropy_bin'] = pd.cut(top1_data['observed_entropy'], bins = entropy_cutoffs_scer, labels = ['L','M','H'])\n",
    "top1_data.loc[top1_data['species'] == 'S.pombe',      'observed_entropy_bin'] = pd.cut(top1_data['observed_entropy'], bins = entropy_cutoffs_spom, labels = ['L','M','H'])\n",
    "top1_data.loc[top1_data['species'] == 'H.sapiens',    'observed_entropy_bin'] = pd.cut(top1_data['observed_entropy'], bins = entropy_cutoffs_hsap, labels = ['L','M','H'])\n",
    "\n",
    "print(\"\\nEntropy group counts by species:\")\n",
    "print(top1_data.groupby('species')['observed_entropy_bin'].value_counts(sort = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESOURCES, 'conservation.top1_sites.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(top1_data, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare conservation data surrounding golden polyA sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify polyA sites in homologous genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.cerevisiae: (11033, 17) 7619 3414\n",
      "S.pombe     : (2387, 17) 1848 539\n",
      "H.sapiens   : (19377, 17) 5563 13814\n"
     ]
    }
   ],
   "source": [
    "gold_scer = pd.read_csv(os.path.join(PROJECT, \"saccharomyces_cerevisiae/analysis/conservation/site_conservation.golden_sites.subset_reads.window_500.txt\"), sep = \"\\t\")\n",
    "gold_spom = pd.read_csv(os.path.join(PROJECT, \"schizosaccharomyces_pombe/analysis/conservation/site_conservation.golden_sites.subset_reads.window_500.txt\"), sep = \"\\t\")\n",
    "gold_hsap = pd.read_csv(os.path.join(PROJECT, \"homo_sapiens/analysis/conservation/site_conservation.golden_sites.subset_reads.window_500.txt\"), sep = \"\\t\")\n",
    "\n",
    "gold_scer = gold_scer.loc[gold_scer['feature'].str.contains('utr3')].copy()\n",
    "gold_spom = gold_spom.loc[gold_spom['feature'].str.contains('utr3')].copy()\n",
    "gold_hsap = gold_hsap.loc[gold_hsap['feature'].str.contains('terminal_exon')].copy()\n",
    "\n",
    "gold_scer['species'] = 'S.cerevisiae'\n",
    "gold_spom['species'] = 'S.pombe'\n",
    "gold_hsap['species'] = 'H.sapiens'\n",
    "\n",
    "gold_scer['featureName'] = gold_scer['gene'].apply(lambda x : scer_synonyms.get(x,np.nan))\n",
    "gold_spom['featureName'] = gold_spom['gene']\n",
    "gold_hsap['featureName'] = gold_hsap['gene'].apply(lambda x : hsap_gene_map.get(x,np.nan))\n",
    "\n",
    "gold_scer['conserved_yeast_to_human'] = gold_scer['featureName'].isin(homologs_scer)\n",
    "gold_spom['conserved_yeast_to_human'] = gold_spom['featureName'].isin(homologs_spom)\n",
    "gold_hsap['conserved_yeast_to_human'] = gold_hsap['featureName'].isin(homologs_hsap)\n",
    "\n",
    "print(\"S.cerevisiae:\", gold_scer.shape, (gold_scer['conserved_yeast_to_human'] == True).sum(), (gold_scer['conserved_yeast_to_human'] == False).sum())\n",
    "print(\"S.pombe     :\", gold_spom.shape, (gold_spom['conserved_yeast_to_human'] == True).sum(), (gold_spom['conserved_yeast_to_human'] == False).sum())\n",
    "print(\"H.sapiens   :\", gold_hsap.shape, (gold_hsap['conserved_yeast_to_human'] == True).sum(), (gold_hsap['conserved_yeast_to_human'] == False).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Category polyA sites based on relative position in the gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11033it [00:01, 9578.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle    4393\n",
      "first     2740\n",
      "last      2740\n",
      "single    1160\n",
      "Name: position, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2387it [00:00, 9543.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single    825\n",
      "last      553\n",
      "first     553\n",
      "middle    456\n",
      "Name: position, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19377it [00:02, 9612.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single    7436\n",
      "first     4479\n",
      "last      4479\n",
      "middle    2983\n",
      "Name: position, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "gold_scer['position'] = calculate_relative_position(gold_scer)\n",
    "print(gold_scer['position'].value_counts())\n",
    "\n",
    "gold_spom['position'] = calculate_relative_position(gold_spom)\n",
    "print(gold_spom['position'].value_counts())\n",
    "\n",
    "gold_hsap['position'] = calculate_relative_position(gold_hsap)\n",
    "print(gold_hsap['position'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate conservation and entropy surrounding polyA sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32797, 20)\n"
     ]
    }
   ],
   "source": [
    "gold_data = pd.concat([gold_scer, gold_spom, gold_hsap], ignore_index = True, sort = False)\n",
    "\n",
    "gold_data['conservation']     = gold_data['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "gold_data['readvec']          = gold_data['readvec'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "gold_data['observed_norm']    = gold_data['readvec'].apply(lambda x: x / np.sum(x))\n",
    "gold_data['observed_entropy'] = gold_data['observed_norm'].apply(lambda x : cleavage.calculate_entropy_from_vector(x))\n",
    "\n",
    "print(gold_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESOURCES, 'conservation.gold_sites.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(gold_data, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conservation of motifs important from PolyaClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare conservation data surrounding top polyA sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify motifs surrounding top sites in homologous genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.cerevisiae: (2732895, 14) 1631520 1101375\n",
      "S.pombe     : (1970100, 14) 1346400 623700\n"
     ]
    }
   ],
   "source": [
    "mot_top1_scer = pd.read_csv(os.path.join(PROJECT, \"saccharomyces_cerevisiae/analysis/conservation/site_conservation.golden_motifs.top-1.window_-1.txt\"), sep = \"\\t\").rename(columns = {'siteKey' : 'posKey'})\n",
    "mot_top1_spom = pd.read_csv(os.path.join(PROJECT, \"schizosaccharomyces_pombe/analysis/conservation/site_conservation.golden_motifs.top-1.window_-1.txt\"), sep = \"\\t\").rename(columns = {'siteKey' : 'posKey'})\n",
    "\n",
    "mot_top1_scer['motif'] = mot_top1_scer['label'].str.split(\"|\").str[0]\n",
    "mot_top1_spom['motif'] = mot_top1_spom['label'].str.split(\"|\").str[0]\n",
    "\n",
    "mot_top1_scer['motifRelPos'] = mot_top1_scer['label'].str.split(\"|\").str[2].astype(int)\n",
    "mot_top1_spom['motifRelPos'] = mot_top1_spom['label'].str.split(\"|\").str[2].astype(int)\n",
    "\n",
    "mot_top1_scer['siteKey'] = mot_top1_scer['label'].apply(lambda x : \":\".join(x.split(\"|\")[1].split(\":\")[1:4]))\n",
    "mot_top1_spom['siteKey'] = mot_top1_spom['label'].apply(lambda x : \":\".join(x.split(\"|\")[1].split(\":\")[1:4]))\n",
    "\n",
    "mot_top1_scer['species'] = 'S.cerevisiae'\n",
    "mot_top1_spom['species'] = 'S.pombe'\n",
    "\n",
    "gene_dict_scer = dict(zip(top1_scer['siteKey'], top1_scer['featureName']))\n",
    "gene_dict_spom = dict(zip(top1_spom['siteKey'], top1_spom['featureName']))\n",
    "\n",
    "mot_top1_scer['featureName'] = mot_top1_scer['siteKey'].apply(lambda x : gene_dict_scer.get(x,np.nan))\n",
    "mot_top1_spom['featureName'] = mot_top1_spom['siteKey'].apply(lambda x : gene_dict_spom.get(x,np.nan))\n",
    "\n",
    "mot_top1_scer['conserved_yeast_to_human'] = mot_top1_scer['featureName'].isin(homologs_scer)\n",
    "mot_top1_spom['conserved_yeast_to_human'] = mot_top1_spom['featureName'].isin(homologs_spom)\n",
    "\n",
    "print(\"S.cerevisiae:\", mot_top1_scer.shape, (mot_top1_scer['conserved_yeast_to_human'] == True).sum(), (mot_top1_scer['conserved_yeast_to_human'] == False).sum())\n",
    "print(\"S.pombe     :\", mot_top1_spom.shape, (mot_top1_spom['conserved_yeast_to_human'] == True).sum(), (mot_top1_spom['conserved_yeast_to_human'] == False).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize motifs by family and significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_top1_scer['motifOverallFamily'] = mot_top1_scer['motif'].apply(lambda x : scer_definitions['distance'][len(x)]['family'].get(x,'Other'))\n",
    "mot_top1_spom['motifOverallFamily'] = mot_top1_spom['motif'].apply(lambda x : spom_definitions['distance'][len(x)]['family'].get(x,'Other'))\n",
    "\n",
    "mot_top1_scer['motifHammingFamily'] = mot_top1_scer['motif'].apply(lambda x : scer_definitions['distance'][len(x)]['hamming'].get(x,'Other'))\n",
    "mot_top1_spom['motifHammingFamily'] = mot_top1_spom['motif'].apply(lambda x : spom_definitions['distance'][len(x)]['hamming'].get(x,'Other'))\n",
    "\n",
    "mot_top1_scer['motifSignificance'] = mot_top1_scer['motif'].isin(sigmots_scer)\n",
    "mot_top1_spom['motifSignificance'] = mot_top1_spom['motif'].isin(sigmots_spom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate mean conservation of each motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4702995, 18)\n"
     ]
    }
   ],
   "source": [
    "mot_top1_data = pd.concat([mot_top1_scer, mot_top1_spom], ignore_index = True, sort = False)\n",
    "\n",
    "mot_top1_data['conservation']         = mot_top1_data['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "mot_top1_data['conservation_mean']    = mot_top1_data['conservation'].apply(lambda x : np.mean(np.nan_to_num(x)))\n",
    "mot_top1_data['conservation_missing'] = mot_top1_data['conservation'].apply(lambda x : np.isnan(x).any())\n",
    "\n",
    "mot_top1_data.drop(columns = ['conservation'], inplace = True)\n",
    "\n",
    "print(mot_top1_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESOURCES, 'conservation.top1_motifs.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(mot_top1_data, handle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare conservation data surrounding golden polyA sites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify motifs surrounding top sites in homologous genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S.cerevisiae: (5778135, 14) 3771405 2006730\n",
      "S.pombe     : (1233540, 14) 914760 318780\n"
     ]
    }
   ],
   "source": [
    "mot_gold_scer = pd.read_csv(os.path.join(PROJECT, \"saccharomyces_cerevisiae/analysis/conservation/site_conservation.golden_motifs.subset_reads.window_-1.txt\"), sep = \"\\t\").rename(columns = {'siteKey' : 'posKey'})\n",
    "mot_gold_spom = pd.read_csv(os.path.join(PROJECT, \"schizosaccharomyces_pombe/analysis/conservation/site_conservation.golden_motifs.subset_reads.window_-1.txt\"), sep = \"\\t\").rename(columns = {'siteKey' : 'posKey'})\n",
    "\n",
    "mot_gold_scer['motif'] = mot_gold_scer['label'].str.split(\"|\").str[0]\n",
    "mot_gold_spom['motif'] = mot_gold_spom['label'].str.split(\"|\").str[0]\n",
    "\n",
    "mot_gold_scer['motifRelPos'] = mot_gold_scer['label'].str.split(\"|\").str[2].astype(int)\n",
    "mot_gold_spom['motifRelPos'] = mot_gold_spom['label'].str.split(\"|\").str[2].astype(int)\n",
    "\n",
    "mot_gold_scer['siteKey'] = mot_gold_scer['label'].apply(lambda x : \":\".join(x.split(\"|\")[1].split(\":\")[1:4]))\n",
    "mot_gold_spom['siteKey'] = mot_gold_spom['label'].apply(lambda x : \":\".join(x.split(\"|\")[1].split(\":\")[1:4]))\n",
    "\n",
    "mot_gold_scer['species'] = 'S.cerevisiae'\n",
    "mot_gold_spom['species'] = 'S.pombe'\n",
    "\n",
    "gene_dict_scer = dict(zip(gold_scer['siteKey'], gold_scer['featureName']))\n",
    "gene_dict_spom = dict(zip(gold_spom['siteKey'], gold_spom['featureName']))\n",
    "\n",
    "mot_gold_scer['featureName'] = mot_gold_scer['siteKey'].apply(lambda x : gene_dict_scer.get(x,np.nan))\n",
    "mot_gold_spom['featureName'] = mot_gold_spom['siteKey'].apply(lambda x : gene_dict_spom.get(x,np.nan))\n",
    "\n",
    "mot_gold_scer['conserved_yeast_to_human'] = mot_gold_scer['featureName'].isin(homologs_scer)\n",
    "mot_gold_spom['conserved_yeast_to_human'] = mot_gold_spom['featureName'].isin(homologs_spom)\n",
    "\n",
    "print(\"S.cerevisiae:\", mot_gold_scer.shape, (mot_gold_scer['conserved_yeast_to_human'] == True).sum(), (mot_gold_scer['conserved_yeast_to_human'] == False).sum())\n",
    "print(\"S.pombe     :\", mot_gold_spom.shape, (mot_gold_spom['conserved_yeast_to_human'] == True).sum(), (mot_gold_spom['conserved_yeast_to_human'] == False).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorize motifs by family and significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot_gold_scer['motifOverallFamily'] = mot_gold_scer['motif'].apply(lambda x : scer_definitions['distance'][len(x)]['family'].get(x,'Other'))\n",
    "mot_gold_spom['motifOverallFamily'] = mot_gold_spom['motif'].apply(lambda x : spom_definitions['distance'][len(x)]['family'].get(x,'Other'))\n",
    "\n",
    "mot_gold_scer['motifHammingFamily'] = mot_gold_scer['motif'].apply(lambda x : scer_definitions['distance'][len(x)]['hamming'].get(x,'Other'))\n",
    "mot_gold_spom['motifHammingFamily'] = mot_gold_spom['motif'].apply(lambda x : spom_definitions['distance'][len(x)]['hamming'].get(x,'Other'))\n",
    "\n",
    "mot_gold_scer['motifSignificance'] = mot_gold_scer['motif'].isin(sigmots_scer)\n",
    "mot_gold_spom['motifSignificance'] = mot_gold_spom['motif'].isin(sigmots_spom)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate mean conservation of each motif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7011675, 19)\n"
     ]
    }
   ],
   "source": [
    "mot_gold_data = pd.concat([mot_gold_scer, mot_gold_spom], ignore_index = True, sort = False)\n",
    "\n",
    "mot_gold_data['conservation']         = mot_gold_data['conservation'].apply(lambda x : np.asarray([float(_) for _ in x.strip(\"][\").split(\",\")]))\n",
    "mot_gold_data['conservation_mean']    = mot_gold_data['conservation'].apply(lambda x : np.mean(np.nan_to_num(x)))\n",
    "mot_gold_data['conservation_missing'] = mot_gold_data['conservation'].apply(lambda x : np.isnan(x).any())\n",
    "\n",
    "print(mot_gold_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data for downstream analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(RESOURCES, 'conservation.gold_motifs.pickle'), mode = 'wb') as handle:\n",
    "    pickle.dump(mot_gold_data, handle)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-train)",
   "language": "python",
   "name": "tf-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
